{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f0889",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/ouday/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ==========================\n",
    "#      CONFIG À ADAPTER\n",
    "# ==========================\n",
    "\n",
    "# Dossier qui contient les splits (train, eval, test, etc.)\n",
    "# Exemple chez toi: C:\\Users\\...\\tuh_eeg_reduit\\tuh_eeg_reduit\\data\n",
    "DATA_ROOT = Path(r\"edf/\")\n",
    "\n",
    "MIN_PREICTAL = 120.0  # seuil pour dire qu'on a ≥ 2 min avant la 1ère crise\n",
    "\n",
    "\n",
    "# ==========================\n",
    "#     FONCTIONS UTILITAIRES\n",
    "# ==========================\n",
    "\n",
    "Interval = Tuple[float, float]\n",
    "\n",
    "\n",
    "def read_duration_from_csv_bi(csv_bi_path: Path) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Lit la durée de l'enregistrement dans les lignes de commentaires du csv_bi.\n",
    "\n",
    "    On cherche une ligne du type:\n",
    "    '# duration = 301.0000 secs'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with csv_bi_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"# duration\"):\n",
    "                    # ex: \"# duration = 301.0000 secs\"\n",
    "                    try:\n",
    "                        parts = line.strip().split(\"=\")\n",
    "                        if len(parts) >= 2:\n",
    "                            right = parts[1].strip()  # \"301.0000 secs\"\n",
    "                            dur_str = right.split()[0]  # \"301.0000\"\n",
    "                            return float(dur_str)\n",
    "                    except Exception:\n",
    "                        return None\n",
    "                # si on a dépassé les commentaires, on arrête\n",
    "                if not line.startswith(\"#\"):\n",
    "                    break\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_seizure_intervals(csv_bi_path: Path) -> List[Interval]:\n",
    "    \"\"\"\n",
    "    Lit le fichier csv_bi (annotations globales) et renvoie la liste des intervalles 'seiz'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_bi_path, comment=\"#\")\n",
    "    if \"label\" not in df.columns or \"start_time\" not in df.columns or \"stop_time\" not in df.columns:\n",
    "        return []\n",
    "    mask = df[\"label\"].astype(str).str.contains(\"seiz\", case=False)\n",
    "    seizures = df[mask]\n",
    "    return [(float(row.start_time), float(row.stop_time)) for row in seizures.itertuples(index=False)]\n",
    "\n",
    "\n",
    "def get_patient_session_from_path(edf_path: Path) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extrait patient et session à partir du chemin TUSZ.\n",
    "    Exemple:\n",
    "      .../train/aaaaaaac/s001_2002/02_tcp_le/aaaaaaac_s001_t000.edf\n",
    "      -> patient = aaaaaaac, session = s001_2002\n",
    "    \"\"\"\n",
    "    parts = edf_path.parts\n",
    "    if len(parts) < 4:\n",
    "        return \"unknown\", \"unknown\"\n",
    "    patient = parts[-4]\n",
    "    session = parts[-3]\n",
    "    return patient, session\n",
    "\n",
    "\n",
    "# ==========================\n",
    "#    PARCOURS ET STATISTIQUES\n",
    "# ==========================\n",
    "\n",
    "def scan_dataset(data_root: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parcourt tous les splits dans data_root et retourne un DataFrame\n",
    "    avec une ligne par enregistrement EDF.\n",
    "    \"\"\"\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Chaque sous-dossier direct de data_root est un split (train, eval, test, ...)\n",
    "    for split_dir in sorted(p for p in data_root.iterdir() if p.is_dir()):\n",
    "        split_name = split_dir.name\n",
    "        print(f\"Scan du split: {split_name}\")\n",
    "\n",
    "        edf_files = sorted(split_dir.rglob(\"*.edf\"))\n",
    "        print(f\"  {len(edf_files)} fichiers EDF trouvés.\")\n",
    "\n",
    "        for edf_path in edf_files:\n",
    "            patient, session = get_patient_session_from_path(edf_path)\n",
    "            recording = edf_path.stem\n",
    "\n",
    "            csv_bi_path = edf_path.with_suffix(\".csv_bi\")\n",
    "            if not csv_bi_path.exists():\n",
    "                # fallback éventuel .csv\n",
    "                alt = edf_path.with_suffix(\".csv\")\n",
    "                if alt.exists():\n",
    "                    csv_bi_path = alt\n",
    "                else:\n",
    "                    print(f\"  [WARN] csv_bi introuvable pour {edf_path}\")\n",
    "                    continue\n",
    "\n",
    "            # Lire durée\n",
    "            duration = read_duration_from_csv_bi(csv_bi_path)\n",
    "\n",
    "            # Lire crises\n",
    "            seizures = read_seizure_intervals(csv_bi_path)\n",
    "            n_seiz = len(seizures)\n",
    "\n",
    "            if n_seiz > 0:\n",
    "                onsets = [s for (s, e) in seizures]\n",
    "                first_onset = float(min(onsets))\n",
    "                total_seiz_dur = float(sum(e - s for (s, e) in seizures))\n",
    "            else:\n",
    "                first_onset = np.nan\n",
    "                total_seiz_dur = 0.0\n",
    "\n",
    "            has_seiz = n_seiz > 0\n",
    "            has_preictal_ge_2min = has_seiz and (first_onset >= MIN_PREICTAL)\n",
    "\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    split=split_name,\n",
    "                    patient=patient,\n",
    "                    session=session,\n",
    "                    recording=recording,\n",
    "                    duration_s=duration,\n",
    "                    n_seizures=n_seiz,\n",
    "                    has_seizure=has_seiz,\n",
    "                    first_seiz_onset_s=first_onset,\n",
    "                    total_seiz_dur_s=total_seiz_dur,\n",
    "                    has_preictal_ge_120s=has_preictal_ge_2min,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_global_stats(df: pd.DataFrame):\n",
    "    print(\"\\n===== STATISTIQUES GLOBALES =====\")\n",
    "\n",
    "    print(\"\\nNombre total d'enregistrements par split :\")\n",
    "    print(df.groupby(\"split\")[\"recording\"].count())\n",
    "\n",
    "    print(\"\\nEnregistrements avec au moins une crise par split :\")\n",
    "    print(df.groupby(\"split\")[\"has_seizure\"].sum())\n",
    "\n",
    "    print(\"\\nEnregistrements avec 1ère crise après 120 s (pré-ictal ≥ 2 min) par split :\")\n",
    "    print(df.groupby(\"split\")[\"has_preictal_ge_120s\"].sum())\n",
    "\n",
    "    print(\"\\nNombre total de crises par split :\")\n",
    "    print(df.groupby(\"split\")[\"n_seizures\"].sum())\n",
    "\n",
    "    print(\"\\nDurée totale de crises (s) par split :\")\n",
    "    print(df.groupby(\"split\")[\"total_seiz_dur_s\"].sum())\n",
    "\n",
    "    # Petite stat globale sur les onsets\n",
    "    has_seiz_df = df[df[\"has_seizure\"]]\n",
    "    if not has_seiz_df.empty:\n",
    "        print(\"\\nTemps de première crise (tous splits confondus) :\")\n",
    "        print(\"  min  :\", has_seiz_df[\"first_seiz_onset_s\"].min())\n",
    "        print(\"  médian :\", has_seiz_df[\"first_seiz_onset_s\"].median())\n",
    "        print(\"  max  :\", has_seiz_df[\"first_seiz_onset_s\"].max())\n",
    "\n",
    "\n",
    "def make_plots(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Produit quelques visualisations simples avec matplotlib.\n",
    "    \"\"\"\n",
    "\n",
    "    # Histogramme des temps de première crise\n",
    "    has_seiz_df = df[df[\"has_seizure\"] & df[\"first_seiz_onset_s\"].notna()]\n",
    "    if not has_seiz_df.empty:\n",
    "        plt.figure()\n",
    "        has_seiz_df[\"first_seiz_onset_s\"].hist(bins=50)\n",
    "        plt.axvline(MIN_PREICTAL, linestyle=\"--\", label=\"120 s\")\n",
    "        plt.title(\"Distribution des temps de première crise\")\n",
    "        plt.xlabel(\"Temps de première crise (s)\")\n",
    "        plt.ylabel(\"Nombre d'enregistrements\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Histogramme des durées d'enregistrement (si les durées sont dispo)\n",
    "    if df[\"duration_s\"].notna().any():\n",
    "        plt.figure()\n",
    "        df[\"duration_s\"].dropna().hist(bins=50)\n",
    "        plt.title(\"Distribution des durées d'enregistrements\")\n",
    "        plt.xlabel(\"Durée (s)\")\n",
    "        plt.ylabel(\"Nombre d'enregistrements\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Barplot : nombre d'enregistrements avec crise par split\n",
    "    plt.figure()\n",
    "    df.groupby(\"split\")[\"has_seizure\"].sum().plot(kind=\"bar\")\n",
    "    plt.title(\"Nombre d'enregistrements avec crises par split\")\n",
    "    plt.ylabel(\"Nombre d'enregistrements\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Barplot : nombre d'enregistrements avec pré-ictal ≥ 2 min par split\n",
    "    plt.figure()\n",
    "    df.groupby(\"split\")[\"has_preictal_ge_120s\"].sum().plot(kind=\"bar\")\n",
    "    plt.title(\"Enregistrements avec pré-ictal ≥ 120 s par split\")\n",
    "    plt.ylabel(\"Nombre d'enregistrements\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not DATA_ROOT.exists():\n",
    "        raise FileNotFoundError(f\"DATA_ROOT introuvable: {DATA_ROOT}\")\n",
    "\n",
    "    print(f\"Racine des données: {DATA_ROOT}\")\n",
    "\n",
    "    df = scan_dataset(DATA_ROOT)\n",
    "\n",
    "    # Sauvegarder aussi les stats brutes si tu veux\n",
    "    out_csv = DATA_ROOT / \"tusz_global_stats.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nDataFrame global sauvegardé dans: {out_csv}\")\n",
    "    print(f\"{len(df)} enregistrements au total.\")\n",
    "\n",
    "    print_global_stats(df)\n",
    "    make_plots(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
