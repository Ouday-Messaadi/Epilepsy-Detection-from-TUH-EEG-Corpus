{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64939816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee9006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca3e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared\\all\\train_sequences_index_balanced.csv\n",
      "CSV utilisé : prepared\\all\\train_sequences_index_balanced.csv\n",
      "                                           path  label   patient    session  \\\n",
      "0  all/sequences/aaaaarjc_s007_t002_seq0083.npy      0  aaaaarjc  s007_2015   \n",
      "1  all/sequences/aaaaaqnr_s001_t000_seq0080.npy      0  aaaaaqnr  s001_2014   \n",
      "2  all/sequences/aaaaaqtw_s002_t011_seq0037.npy      1  aaaaaqtw  s002_2014   \n",
      "3  all/sequences/aaaaanme_s010_t010_seq0105.npy      0  aaaaanme  s010_2014   \n",
      "4  all/sequences/aaaaaqvx_s002_t001_seq0199.npy      0  aaaaaqvx  s002_2015   \n",
      "\n",
      "            recording  last_win_center_s  \n",
      "0  aaaaarjc_s007_t002              186.0  \n",
      "1  aaaaaqnr_s001_t000              180.0  \n",
      "2  aaaaaqtw_s002_t011              156.0  \n",
      "3  aaaaanme_s010_t010              572.0  \n",
      "4  aaaaaqvx_s002_t001             2658.0  \n",
      "Taille CSV : 9546\n",
      "label\n",
      "0    4773\n",
      "1    4773\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PREPARED_ROOT = Path(\"prepared/\")          # dossier racine de sortie du préprocessing\n",
    "SPLIT = \"all\"                           # on a tout mis dans un seul split logique\n",
    "CSV_NAME = \"train_sequences_index_balanced.csv\" # nom du CSV équilibré\n",
    "\n",
    "csv_path = PREPARED_ROOT / SPLIT / CSV_NAME\n",
    "print(csv_path)\n",
    "print(\"CSV utilisé :\", csv_path)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.head())\n",
    "print(\"Taille CSV :\", len(df))\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54fc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de patients uniques : 91\n"
     ]
    }
   ],
   "source": [
    "PATIENT_COL = \"patient\"   # nom de la colonne patient dans ton CSV\n",
    "\n",
    "if PATIENT_COL not in df.columns:\n",
    "    raise ValueError(f\"La colonne '{PATIENT_COL}' est absente du CSV. Vérifie le nom des colonnes.\")\n",
    "\n",
    "patients = df[PATIENT_COL].unique()\n",
    "print(\"Nombre de patients uniques :\", len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f070fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(patients)\n",
    "\n",
    "n_patients = len(patients)\n",
    "n_train = int(0.6 * n_patients)\n",
    "n_val   = int(0.2 * n_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c07ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille train : 6117\n",
      "Taille val   : 1797\n",
      "Taille test  : 1632\n",
      "\n",
      "Distribution des labels (train)\n",
      "label\n",
      "0    3244\n",
      "1    2873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des labels (val)\n",
      "label\n",
      "1    957\n",
      "0    840\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des labels (test)\n",
      "label\n",
      "1    943\n",
      "0    689\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_patients = patients[:n_train]\n",
    "val_patients   = patients[n_train:n_train + n_val]\n",
    "test_patients  = patients[n_train + n_val:]\n",
    "\n",
    "def filter_by_patients(df, allowed_patients):\n",
    "    return df[df[PATIENT_COL].isin(allowed_patients)].reset_index(drop=True)\n",
    "\n",
    "df_train = filter_by_patients(df, train_patients)\n",
    "df_val   = filter_by_patients(df, val_patients)\n",
    "df_test  = filter_by_patients(df, test_patients)\n",
    "\n",
    "print(\"Taille train :\", len(df_train))\n",
    "print(\"Taille val   :\", len(df_val))\n",
    "print(\"Taille test  :\", len(df_test))\n",
    "\n",
    "print(\"\\nDistribution des labels (train)\")\n",
    "print(df_train[\"label\"].value_counts())\n",
    "print(\"\\nDistribution des labels (val)\")\n",
    "print(df_val[\"label\"].value_counts())\n",
    "print(\"\\nDistribution des labels (test)\")\n",
    "print(df_test[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b2c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train : 765\n",
      "Batches val   : 225\n",
      "Batches test  : 204\n",
      "Shape batch_x : torch.Size([8, 27, 10, 40, 7])\n",
      "Shape batch_y : torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\pyTorch\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "FIXED_N_CHANNELS = 27\n",
    "\n",
    "class SeizureSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour les séquences de spectrogrammes.\n",
    "    Chaque fichier npy a la forme [seq_len, C_i, F, T] (C_i variable).\n",
    "    On impose une forme finale [FIXED_N_CHANNELS, seq_len, F, T]\n",
    "      - si C_i > FIXED_N_CHANNELS -> on tronque\n",
    "      - si C_i < FIXED_N_CHANNELS -> on pad avec des zéros\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, prepared_root: Path, fixed_n_channels: int = FIXED_N_CHANNELS):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.prepared_root = prepared_root\n",
    "        self.fixed_n_channels = fixed_n_channels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        row = self.df.iloc[idx]\n",
    "        rel_path = row[\"path\"]\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        npy_path = self.prepared_root / rel_path\n",
    "        arr = np.load(npy_path)               # [seq_len, C_i, F, T]\n",
    "        arr = arr.astype(np.float32)\n",
    "\n",
    "        # Réorganiser en [C_i, seq_len, F, T]\n",
    "        arr = np.transpose(arr, (1, 0, 2, 3))\n",
    "        C_i, N, Freq, Time = arr.shape\n",
    "\n",
    "        # Ajuster le nombre de canaux à FIXED_N_CHANNELS\n",
    "        if C_i > self.fixed_n_channels:\n",
    "            # On garde les premiers canaux\n",
    "            arr = arr[:self.fixed_n_channels, :, :, :]\n",
    "        elif C_i < self.fixed_n_channels:\n",
    "            # On pad avec des zéros sur les canaux manquants\n",
    "            pad_c = self.fixed_n_channels - C_i\n",
    "            pad_width = ((0, pad_c), (0, 0), (0, 0), (0, 0))\n",
    "            arr = np.pad(arr, pad_width, mode=\"constant\", constant_values=0.0)\n",
    "\n",
    "        assert arr.shape[0] == self.fixed_n_channels, f\"Shape canaux incorrecte : {arr.shape}\"\n",
    "\n",
    "        x = torch.from_numpy(arr)                  # [C_fix, N, F, T]\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Création des datasets / dataloaders\n",
    "# -------------------------------------------------------------------\n",
    "train_dataset = SeizureSequenceDataset(df_train, PREPARED_ROOT, fixed_n_channels=FIXED_N_CHANNELS)\n",
    "val_dataset   = SeizureSequenceDataset(df_val,   PREPARED_ROOT, fixed_n_channels=FIXED_N_CHANNELS)\n",
    "test_dataset  = SeizureSequenceDataset(df_test,  PREPARED_ROOT, fixed_n_channels=FIXED_N_CHANNELS)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=0, pin_memory=True)\n",
    "\n",
    "print(\"Batches train :\", len(train_loader))\n",
    "print(\"Batches val   :\", len(val_loader))\n",
    "print(\"Batches test  :\", len(test_loader))\n",
    "\n",
    "# Vérification d'un batch\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(\"Shape batch_x :\", batch_x.shape)  # (B, C_fix, N, F, T)\n",
    "print(\"Shape batch_y :\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fad6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_fix, N, Freq, Time : 27 10 40 7\n",
      "Sortie modèle (shape): torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "class Seizure3DCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int, base_filters: int = 16, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Bloc 1 : Conv3D + BN + ReLU + MaxPool3D (sur F et T uniquement)\n",
    "        self.conv1 = nn.Conv3d(in_channels, base_filters,\n",
    "                               kernel_size=(3, 3, 3),\n",
    "                               padding=(1, 1, 1))\n",
    "        self.bn1 = nn.BatchNorm3d(base_filters)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2),\n",
    "                                  stride=(1, 2, 2))   # D (N) inchangé, F/T divisés par ~2\n",
    "\n",
    "        # Bloc 2 : Conv3D + BN + ReLU + MaxPool3D (réduction sur D, F, T)\n",
    "        self.conv2 = nn.Conv3d(base_filters, base_filters * 2,\n",
    "                               kernel_size=(3, 3, 3),\n",
    "                               padding=(1, 1, 1))\n",
    "        self.bn2 = nn.BatchNorm3d(base_filters * 2)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2),\n",
    "                                  stride=(2, 2, 2))   # D, F, T divisés par ~2\n",
    "\n",
    "        # Bloc 3 : Conv3D + BN + ReLU (pas de pooling pour éviter T -> 0)\n",
    "        self.conv3 = nn.Conv3d(base_filters * 2, base_filters * 4,\n",
    "                               kernel_size=(3, 3, 3),\n",
    "                               padding=(1, 1, 1))\n",
    "        self.bn3 = nn.BatchNorm3d(base_filters * 4)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Classification finale\n",
    "        self.fc = nn.Linear(base_filters * 4, 2)   # 2 classes (preictal / interictal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [B, C_fix, N, F, T]\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))  # -> [B, F1, N, F1', T1']\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))  # -> [B, F2, N2, F2', T2']\n",
    "        x = F.relu(self.bn3(self.conv3(x)))              # -> [B, F3, N3, F3', T3']\n",
    "\n",
    "        # Global average pooling sur les dimensions (N3, F3', T3')\n",
    "        x = x.mean(dim=[2, 3, 4])    # -> [B, F3]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)               # -> [B, 2]\n",
    "        return x\n",
    "\n",
    "\n",
    "# Test rapide avec un batch\n",
    "C_fix, N, Freq, Time = batch_x.shape[1:]\n",
    "print(\"C_fix, N, Freq, Time :\", C_fix, N, Freq, Time)\n",
    "\n",
    "model_test = Seizure3DCNN(in_channels=C_fix, base_filters=16, dropout=0.5).to(device)\n",
    "out = model_test(batch_x.to(device))\n",
    "print(\"Sortie modèle (shape):\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850de383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)   # [B, C_fix, N, F, T]\n",
    "        y = y.to(device)   # [B]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)              # [B, 2]\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            running_correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8811011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de configs à tester : 8\n",
      "\n",
      "===== Config 1/8 =====\n",
      "{'base_filters': 16, 'dropout': 0.3, 'lr': 0.001}\n",
      "  Epoch 1/5 - Train loss: 0.5712, acc: 0.698 | Val loss: 1.2807, acc: 0.459\n",
      "  Epoch 2/5 - Train loss: 0.3994, acc: 0.824 | Val loss: 1.0786, acc: 0.499\n",
      "  Epoch 3/5 - Train loss: 0.2926, acc: 0.881 | Val loss: 1.4746, acc: 0.501\n",
      "  Epoch 4/5 - Train loss: 0.2268, acc: 0.910 | Val loss: 1.6145, acc: 0.457\n",
      "  Epoch 5/5 - Train loss: 0.1706, acc: 0.934 | Val loss: 1.7552, acc: 0.508\n",
      "\n",
      "===== Config 2/8 =====\n",
      "{'base_filters': 16, 'dropout': 0.3, 'lr': 0.0003}\n",
      "  Epoch 1/5 - Train loss: 0.5614, acc: 0.692 | Val loss: 0.9653, acc: 0.527\n",
      "  Epoch 2/5 - Train loss: 0.3425, acc: 0.860 | Val loss: 0.9542, acc: 0.525\n",
      "  Epoch 3/5 - Train loss: 0.2096, acc: 0.925 | Val loss: 1.6489, acc: 0.492\n",
      "  Epoch 4/5 - Train loss: 0.1616, acc: 0.940 | Val loss: 1.7659, acc: 0.445\n",
      "  Epoch 5/5 - Train loss: 0.1221, acc: 0.957 | Val loss: 2.0133, acc: 0.522\n",
      "\n",
      "===== Config 3/8 =====\n",
      "{'base_filters': 16, 'dropout': 0.5, 'lr': 0.001}\n",
      "  Epoch 1/5 - Train loss: 0.5719, acc: 0.694 | Val loss: 0.9333, acc: 0.497\n",
      "  Epoch 2/5 - Train loss: 0.4053, acc: 0.818 | Val loss: 1.2667, acc: 0.480\n",
      "  Epoch 3/5 - Train loss: 0.2997, acc: 0.873 | Val loss: 1.6285, acc: 0.472\n",
      "  Epoch 4/5 - Train loss: 0.1994, acc: 0.926 | Val loss: 1.9019, acc: 0.478\n",
      "  Epoch 5/5 - Train loss: 0.1927, acc: 0.926 | Val loss: 2.1269, acc: 0.452\n",
      "\n",
      "===== Config 4/8 =====\n",
      "{'base_filters': 16, 'dropout': 0.5, 'lr': 0.0003}\n",
      "  Epoch 1/5 - Train loss: 0.5669, acc: 0.685 | Val loss: 0.9712, acc: 0.483\n",
      "  Epoch 2/5 - Train loss: 0.3453, acc: 0.863 | Val loss: 1.5778, acc: 0.482\n",
      "  Epoch 3/5 - Train loss: 0.2384, acc: 0.909 | Val loss: 1.4145, acc: 0.482\n",
      "  Epoch 4/5 - Train loss: 0.1723, acc: 0.938 | Val loss: 1.4377, acc: 0.529\n",
      "  Epoch 5/5 - Train loss: 0.1349, acc: 0.954 | Val loss: 2.3089, acc: 0.503\n",
      "\n",
      "===== Config 5/8 =====\n",
      "{'base_filters': 32, 'dropout': 0.3, 'lr': 0.001}\n",
      "  Epoch 1/5 - Train loss: 0.5736, acc: 0.682 | Val loss: 2.0810, acc: 0.482\n",
      "  Epoch 2/5 - Train loss: 0.4057, acc: 0.816 | Val loss: 1.9789, acc: 0.459\n",
      "  Epoch 3/5 - Train loss: 0.2939, acc: 0.879 | Val loss: 1.8465, acc: 0.467\n",
      "  Epoch 4/5 - Train loss: 0.2195, acc: 0.916 | Val loss: 3.1655, acc: 0.478\n",
      "  Epoch 5/5 - Train loss: 0.1665, acc: 0.936 | Val loss: 1.9949, acc: 0.487\n",
      "\n",
      "===== Config 6/8 =====\n",
      "{'base_filters': 32, 'dropout': 0.3, 'lr': 0.0003}\n",
      "  Epoch 1/5 - Train loss: 0.5268, acc: 0.725 | Val loss: 1.4596, acc: 0.481\n",
      "  Epoch 2/5 - Train loss: 0.3008, acc: 0.874 | Val loss: 1.5081, acc: 0.515\n",
      "  Epoch 3/5 - Train loss: 0.1846, acc: 0.930 | Val loss: 1.9154, acc: 0.488\n",
      "  Epoch 4/5 - Train loss: 0.1489, acc: 0.945 | Val loss: 4.1871, acc: 0.493\n",
      "  Epoch 5/5 - Train loss: 0.1124, acc: 0.959 | Val loss: 2.6590, acc: 0.493\n",
      "\n",
      "===== Config 7/8 =====\n",
      "{'base_filters': 32, 'dropout': 0.5, 'lr': 0.001}\n",
      "  Epoch 1/5 - Train loss: 0.5725, acc: 0.688 | Val loss: 0.9749, acc: 0.455\n",
      "  Epoch 2/5 - Train loss: 0.3827, acc: 0.830 | Val loss: 2.2206, acc: 0.475\n",
      "  Epoch 3/5 - Train loss: 0.2774, acc: 0.884 | Val loss: 1.3930, acc: 0.469\n",
      "  Epoch 4/5 - Train loss: 0.2104, acc: 0.915 | Val loss: 1.4664, acc: 0.469\n",
      "  Epoch 5/5 - Train loss: 0.1715, acc: 0.933 | Val loss: 1.8539, acc: 0.493\n",
      "\n",
      "===== Config 8/8 =====\n",
      "{'base_filters': 32, 'dropout': 0.5, 'lr': 0.0003}\n",
      "  Epoch 1/5 - Train loss: 0.5320, acc: 0.722 | Val loss: 1.6043, acc: 0.500\n",
      "  Epoch 2/5 - Train loss: 0.3233, acc: 0.867 | Val loss: 1.2976, acc: 0.530\n",
      "  Epoch 3/5 - Train loss: 0.2183, acc: 0.914 | Val loss: 1.7081, acc: 0.505\n",
      "  Epoch 4/5 - Train loss: 0.1654, acc: 0.938 | Val loss: 2.4702, acc: 0.476\n",
      "  Epoch 5/5 - Train loss: 0.1318, acc: 0.952 | Val loss: 3.1573, acc: 0.505\n",
      "\n",
      "===== Meilleure config trouvée =====\n",
      "{'base_filters': 16, 'dropout': 0.3, 'lr': 0.0003}\n",
      "Best val acc : 0.5224274406332454\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"base_filters\": [16, 32],\n",
    "    \"dropout\": [0.3, 0.5],\n",
    "    \"lr\": [1e-3, 3e-4]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "print(\"Nombre de configs à tester :\", len(grid))\n",
    "\n",
    "N_EPOCHS_SEARCH = 5   # tu peux augmenter plus tard\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_config = None\n",
    "best_state_dict = None\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "C_fix = FIXED_N_CHANNELS\n",
    "\n",
    "for i, params in enumerate(grid):\n",
    "    print(f\"\\n===== Config {i+1}/{len(grid)} =====\")\n",
    "    print(params)\n",
    "\n",
    "    # nouveau modèle pour chaque config\n",
    "    model = Seizure3DCNN(\n",
    "        in_channels=C_fix,\n",
    "        base_filters=params[\"base_filters\"],\n",
    "        dropout=params[\"dropout\"],\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params[\"lr\"],\n",
    "        weight_decay=1e-4,    # L2 léger\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS_SEARCH + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"  Epoch {epoch}/{N_EPOCHS_SEARCH} - \"\n",
    "              f\"Train loss: {train_loss:.4f}, acc: {train_acc:.3f} | \"\n",
    "              f\"Val loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n",
    "\n",
    "    # on garde la meilleure config selon la dernière val_acc\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_config = params\n",
    "        best_state_dict = model.state_dict()\n",
    "\n",
    "print(\"\\n===== Meilleure config trouvée =====\")\n",
    "print(best_config)\n",
    "print(\"Best val acc :\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\pyTorch\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train loss: 0.5473, acc: 0.700 | Val loss: 1.1719, acc: 0.504\n",
      "  -> Nouveau meilleur modèle sauvegardé.\n",
      "Epoch 2/20 - Train loss: 0.3312, acc: 0.862 | Val loss: 1.3441, acc: 0.503\n",
      "Epoch 3/20 - Train loss: 0.2117, acc: 0.915 | Val loss: 1.4210, acc: 0.490\n",
      "Epoch 4/20 - Train loss: 0.1446, acc: 0.949 | Val loss: 1.5470, acc: 0.504\n",
      "Epoch 5/20 - Train loss: 0.1212, acc: 0.957 | Val loss: 2.8695, acc: 0.494\n",
      "Epoch 6/20 - Train loss: 0.1040, acc: 0.962 | Val loss: 1.6452, acc: 0.502\n",
      "  -> Early stopping déclenché.\n",
      "\n",
      "Entraînement terminé.\n",
      "Meilleur modèle enregistré dans : models/best_cnn3d_tuh.pth\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS_FINAL = 20\n",
    "PATIENCE = 5\n",
    "MODEL_SAVE_PATH = \"models/best_cnn3d_tuh.pth\"\n",
    "\n",
    "if best_config is None:\n",
    "    raise RuntimeError(\"Aucune config n'a été trouvée pendant le grid search.\")\n",
    "\n",
    "\n",
    "model = Seizure3DCNN(\n",
    "    in_channels=FIXED_N_CHANNELS,                 # ✅ PAS C\n",
    "    base_filters=best_config[\"base_filters\"],\n",
    "    dropout=best_config[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=best_config[\"lr\"],\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, N_EPOCHS_FINAL + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{N_EPOCHS_FINAL} - \"\n",
    "          f\"Train loss: {train_loss:.4f}, acc: {train_acc:.3f} | \"\n",
    "          f\"Val loss: {val_loss:.4f}, acc: {val_acc:.3f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"  -> Nouveau meilleur modèle sauvegardé.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"  -> Early stopping déclenché.\")\n",
    "            break\n",
    "\n",
    "print(\"\\nEntraînement terminé.\")\n",
    "print(\"Meilleur modèle enregistré dans :\", MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b962014",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Seizure3DCNN(\n",
    "    in_channels=FIXED_N_CHANNELS,\n",
    "    base_filters=best_config[\"base_filters\"],\n",
    "    dropout=best_config[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        outputs = best_model(x)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "test_acc = accuracy_score(all_targets, all_preds)\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "report = classification_report(all_targets, all_preds, digits=3)\n",
    "\n",
    "print(\"Test accuracy :\", test_acc)\n",
    "print(\"\\nConfusion matrix :\\n\", cm)\n",
    "print(\"\\nClassification report :\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
